## CDN技术方案探索
### 内容请求流程
![](./src/CDN架构/CDN架构探索-请求流程.jpg)

#### 超级节点
这里的超级节点，不是PTFS节点中的`SMINER`，而是处理能力(计算能力，上下行能力)比较强的CDN节点。
这里我们把这一层节点当成一个`动态层`。
- 动态
即数量可变，能随时增减。
当西柚机节点数量不够时，可以增加数量，能保证我们提供的服务的下限；当西柚机节点数量上升后，可减少节点数量，减少运营开支；

#### 优化延迟
在`直播`业务中，对延时的要求比较高。当层次越多，自然延时就越大。
这里数据的最大延迟为`源站`-`动态层`-`西柚机节点`-`客户端`。

#### 流程统一
直播，点播，使用同一套流程。

#### 请求流程
- 流程`4`中，当未命中(附近的节点没有数据时)，需要超级节点参与(保证秒开)，与此同时，附近的西柚机也开始请求数据，当附近的数据足够，则断开与超级节点的连接；

### 直播
直播与点播有所不同，点播的资源是确定的，在一开始就可以知道接下来所有要播放的内容，并且有索引文件标记所有的分片；
直播是数据流，当前并不知道下一刻要播放的内容，所以，不能用`ipfs`的`内容寻址`(即便可以，延时也非常大)；

#### 内容定位
直播不太容易使用`ipfs`的分片下载是因为下一刻要下载的分片内容不确定，也就是`hash`不确定。
但是，直播的数据流在传输过程中也是数据包的格式，若结合`url`+`packageID`，是不是就可以确定未来要播放的内容？

![](./src/CDN架构/直播P2P方案.jpg)

- 超级节点拉流时，给所有数据包打上ID。
- 使用`url`+`id`来唯一定位分片。
- 模拟`ipfs`，给附近的节点发送`wantlist`，只是不是hash，是`url`+`id`。
- 收到wantlist, 若在缓存中，直接返回数据；若小于缓存，则返回错误；若大于缓存，等该包到达时，发送该包给对应节点。
- 收到一个id后，给附近有该直播流的节点分别发送`id+n`的wantlist。

## 技术点
- P2P技术深入
- 传输流程统一化
- 直播P2P验证

